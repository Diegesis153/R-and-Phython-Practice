# Journals & CPS1985 Analysis
This repository contains R code for:
- Scatterplots & OLS regression for `Journals` dataset (AER package)
- Quantile regression & kernel density estimation for `CPS1985` dataset (AER package)

## Packages Required
- AER
- quantreg
- KernSmooth

## Data Sources
- AER R package: `Journals`, `CPS1985`


-----------


data("Journals", package = "AER")
dim(Journals)
names(Journals)
plot(log(subs) ~log(price/citations), data = Journals)
j_lm <- lm(log(subs) ~ log(price/citations), data = Journals)
abline(j_lm)
#The abline() command adds the least-squres line to the existing scatter plot;
summary(j_lm)

#For the journals regression, the estimated elasticity of the demand with respect to the price per citation is -0.5331.
# The R^2 = 0.557 looks satisfactory for a cross-section regression.

#another examples

data("CPS1985", package = "AER")
cps <- CPS1985
library("quantreg")
cps_lm <- lm(log(wage) ~ experience + I(experience^2) + education, data = cps)
# Estimate a multiple linear regression model by OLS(lm()).
cps_rq <- rq(log(wage) ~ experience + I(experience ^2) + education, data = cps, tau = seq(0.2, 0.8, by = 0.15))
# Quantile regressions are fitted using the function rq()
# Quantile regression model provides a more complete view of the entire conditional distribution (by choosing selecgted quantiles), not just the conditional mean.
# In the case of quantile regression models, we should specify data argument "tau", the set of quantiles that are to be modeled ( in our case, this argument will be set to 0.2, 0.35, 0.5, 0.65, 0.8)

#we compute predictions from both models for a new data set cps2, where education is held constant at its mean and experience varies over the range of the original variable.

cps2 <- data.frame(education = mean(cps$education), experience = min(cps$experience):max(cps$experience))
cps2 <- cbind(cps2, 
            predict(cps_lm, newdata = cps2, interval = "prediction"))
cps2 <- cbind(cps2, 
               predict(cps_rq, newdata = cps2, type = ""))
plot(log(wage) ~ experience, data = cps)
for(i in 6:10) lines(cps2[,i] ~ experience, 
                     data = cps2, col = "red")
# 1️⃣ for(i in 6:10)
# - 'i' repeats from 6 to 10
# - In other words, it processes columns 6 through 10 of the cps2 data frame one by one

#  cps2[,i] ~ experience
# - cps2[,i] selects the i-th column of the cps2 data frame
# - experience is used as the x-axis values
# - In short, this draws a line with the i-th column as y-values and experience as x-values

plot(summary(cps_rq))

# This plot shows how the regression coefficients change across different quantiles,
# along with the least-squares estimates. Both include 90% confidence intervals.
# 
# Key points:
# - The 'experience' coefficients gradually decrease in absolute value as the quantile increases
#   (the quadratic term has a negative coefficient), resulting in a flatter curve at higher quantiles.
# - The intercept increases with the quantile.
# - The effect of 'education' remains relatively stable across quantiles.



# Problem: Scatterplots may hide data points when many observations overlap.
# Solution: Use bivariate kernel density estimation to estimate the density 
#           at each point in the two-dimensional space.
# Visualization: Display as a heatmap, where color intensity shows point density.

library("KernSmooth")
cps_bkde <- bkde2D(cbind(cps$experience, log(cps$wage)),
                   bandwidth = c(3.5, 0.5), gridsize = c(200, 200))
# Load the KernSmooth package, which provides bkde2D() for 2D kernel density estimation
# Create a 2D data matrix with experience and log(wage) using cbind()
# Set bandwidths for smoothing: 3.5 for experience, 0.5 for log(wage)
# Set a grid of 200x200 points to evaluate the density
# Store the resulting 2D kernel density estimate matrix in cps_bkde

image(cps_bkde$x1, cps_bkde$x2, cps_bkde$fhat,
      col = rev(gray.colors(10, gamma =1)),
      xlab = "experience", ylab = "log(wage)")
# Draw a heatmap of the bivariate kernel density estimate
# Draw a heatmap showing the 2D distribution of experience and log(wage)
# using a bivariate kernel density estimate.
# Darker colors indicate regions with higher data density,
# allowing us to see where most observations are concentrated.
# x-axis: experience, y-axis: log(wage)
# cps_bkde$fhat contains the density estimates at each grid point
# Darker shades (using rev(gray.colors(10))) indicate higher density

box()
lines(fit ~ experience, data = cps2)
lines(lwr ~ experience, data = cps2, lty = 2)
lines(upr ~ experience, data = cps2, lty = 2)
